<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="zFdqsZQCJwF_Ibxc_vjqqAf1qXYxoPrqGeYVUHD2J9M" />










  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  







<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="雷德麥的藏書閣" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="title: 以 gensim 訓練中文詞向量date: 2016-08-28 00:56:23tags:
- Word Embedding
- Word2Vec
- gensim
categories:
- 自然語言處理

最近想嘗試幾種文本分類的算法，卻一直苦於沒有結構化的中文語料，原本是打算先爬下大把大把的部落格文章，再依 tag 將它們分門別類，可惜試了一陣子後，我見識到了理想和現實間的鴻">
<meta property="og:type" content="article">
<meta property="og:title" content="雷德麥的藏書閣">
<meta property="og:url" content="http://zake7749.github.io/2016/10/25/word2vec-with-gensim/index.html">
<meta property="og:site_name" content="雷德麥的藏書閣">
<meta property="og:description" content="title: 以 gensim 訓練中文詞向量date: 2016-08-28 00:56:23tags:
- Word Embedding
- Word2Vec
- gensim
categories:
- 自然語言處理

最近想嘗試幾種文本分類的算法，卻一直苦於沒有結構化的中文語料，原本是打算先爬下大把大把的部落格文章，再依 tag 將它們分門別類，可惜試了一陣子後，我見識到了理想和現實間的鴻">
<meta property="og:image" content="http://i.imgur.com/VnjnW7S.jpg">
<meta property="og:image" content="http://i.imgur.com/KR2ISOg.jpg">
<meta property="og:updated_time" content="2016-10-24T16:31:40.290Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雷德麥的藏書閣">
<meta name="twitter:description" content="title: 以 gensim 訓練中文詞向量date: 2016-08-28 00:56:23tags:
- Word Embedding
- Word2Vec
- gensim
categories:
- 自然語言處理

最近想嘗試幾種文本分類的算法，卻一直苦於沒有結構化的中文語料，原本是打算先爬下大把大把的部落格文章，再依 tag 將它們分門別類，可惜試了一陣子後，我見識到了理想和現實間的鴻">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://zake7749.github.io/2016/10/25/word2vec-with-gensim/"/>

  <title>  | 雷德麥的藏書閣 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      <a class="menu-item website-text-logo" href="/">
        <b class="text-logo-eg">R</b><span class="text-logo-ch"><h1 class="site-title">雷德麥的藏書閣</h1></span>
      </a>
      
        
        <a class="menu-item menu-item-categories red-tooltip" href="/categories" data-toggle="tooltip" title="文章目錄">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i>
              <span class="sidebar-title">文章目錄</span>
            
          </a>
      
        
        <a class="menu-item menu-item-archives red-tooltip" href="/archives" data-toggle="tooltip" title="文章歸檔">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i>
              <span class="sidebar-title">文章歸檔</span>
            
          </a>
      
        
        <a class="menu-item menu-item-tags red-tooltip" href="/tags" data-toggle="tooltip" title="特色標籤">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i>
              <span class="sidebar-title">特色標籤</span>
            
          </a>
      

      
    </ul>
  

  
</nav>
 </div>
      <ul id="btm-menu" class="menu cus-menu">
        <a id="cus-object-group" href="https://csienckugrade3.hackpad.com/" class="menu-item cus-menu-fontbtn" data-toggle="tooltip" title="CS Notes">
          <i class="menu-item-icon fa fa fa-object-group"></i>
          <span class="sidebar-title">CS Note pads</span>
        </a>
        <a id="cus-map" href="#" class="menu-item cus-menu-fontbtn" data-toggle="tooltip" title="關閉側邊欄">
          <i class="menu-item-icon fa fa-map"></i>
          <span class="sidebar-title">關閉側邊欄</span>
        </a>
        <a id="cus-lightbulb" href="#" class="menu-item cus-menu-fontbtn" data-toggle="tooltip" title="施工中 ─=≡Σ(((っﾟДﾟ)っ">
          <i class="menu-item-icon fa fa-lightbulb-o"></i>
          <span class="sidebar-title">顯示模式</span>
        </a>
      </ul>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal  post-index-border" itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">發表於</span>
            <time itemprop="dateCreated" datetime="2016-10-25T00:31:40+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/25/word2vec-with-gensim/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/10/25/word2vec-with-gensim/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>title: 以 gensim 訓練中文詞向量<br>date: 2016-08-28 00:56:23<br>tags:</p>
<pre><code>- Word Embedding
- Word2Vec
- gensim
</code></pre><p>categories:</p>
<pre><code>- 自然語言處理
</code></pre><hr>
<p>最近想嘗試幾種文本分類的算法，卻一直苦於沒有結構化的中文語料，原本是打算先爬下大把大把的部落格文章，再依 tag 將它們分門別類，可惜試了一陣子後，我見識到了理想和現實間的鴻溝。</p>
<p><img src="http://i.imgur.com/VnjnW7S.jpg" alt="太麻煩的事我不會做"></p>
<p class="img-meta"><a href="https://github.com/zake7749/PTT-Text-Mining" target="_blank" rel="external">儘管後來還是搞定了</a></p>

<p>所以就找上了基於非監督學習的 word2vec，為了銜接後續的資料處理，這邊採用的是基於 python 的主題模型函式庫 <a href="https://radimrehurek.com/gensim/" target="_blank" rel="external">gensim</a>。這篇教學並不會談太多 word2vec 的數學原理，而是考慮如何輕鬆又直覺地訓練中文詞向量，文章裡所有的程式碼都會傳上 <a href="https://github.com/zake7749/word2vec_tutorial" target="_blank" rel="external">github</a>，現在，就讓我們進入正題吧。</p>
<a id="more"></a>
<h2 id="u53D6_u5F97_u8A9E_u6599"><a href="#u53D6_u5F97_u8A9E_u6599" class="headerlink" title="取得語料"></a>取得語料</h2><p>要訓練詞向量，第一步當然是取得資料集。由於 word2vec 是基於非監督式學習，訓練集一定一定要越大越好，語料涵蓋的越全面，訓練出來的結果也會越漂亮。我所採用的是維基百科於<a href="https://dumps.wikimedia.org/zhwiki/20160820/zhwiki-20160820-pages-articles.xml.bz2" target="_blank" rel="external">2016/08/20的備份</a>，文章篇數共有 2822639 篇，如果需要更近期的數據，可以前往<a href="https://zh.wikipedia.org/wiki/Wikipedia:%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8B%E8%BD%BD" target="_blank" rel="external">維基百科:資料庫下載</a>，不過請特別注意一點，要挑選的是以 <code>pages-articles.xml.bz2</code> 結尾的備份，而不是以 <code>pages-articles-multistream.xml.bz2</code> 結尾的備份唷，不然會在清理上出現一些異常，無法正常解析文章。</p>
<p>在等待下載的這段時間，我們可以先把這次的主角<code>gensim</code>配置好:</p>
<pre><code>pip3 install --upgrade gensim
</code></pre><p>維基百科下載好後，先別急著解壓縮，因為這是一份 xml 文件，裏頭佈滿了各式各樣的標籤，我們得先想辦法送走這群不速之客，不過也別太擔心，gensim 早已看穿了一切，藉由調用 <a href="https://radimrehurek.com/gensim/corpora/wikicorpus.html" target="_blank" rel="external">wikiCorpus</a>，我們能很輕鬆的只取出文章的標題和內容：</p>
<p>初始化<code>WikiCorpus</code>後，能藉由<code>get_texts()</code>可迭代每一篇文章，它所回傳的是一個tokens list，我以空白符將這些 tokens 串接起來，統一輸出到同一份文字檔裡。這邊要注意一件事，<code>get_texts()</code>受<code>wikicorpus.py</code>中的變數<code>ARTICLE_MIN_WORDS</code>限制，只會回傳內容長度大於 <em>50</em> 的文章。</p>
<pre><code class="python"><span class="comment"># -*- coding: utf-8 -*-</span>
<span class="keyword">import</span> logging
<span class="keyword">import</span> sys

<span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> WikiCorpus

<span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span>

    <span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:
        print(<span class="string">"Usage: python3 "</span> + sys.argv[<span class="number">0</span>] + <span class="string">" wiki_data_path"</span>)
        exit()

    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)
    wiki_corpus = WikiCorpus(sys.argv[<span class="number">1</span>], dictionary={})
    texts_num = <span class="number">0</span>

    <span class="keyword">with</span> open(<span class="string">"wiki_texts.txt"</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> output:
        <span class="keyword">for</span> text <span class="keyword">in</span> wiki_corpus.get_texts():
            output.write(<span class="string">b' '</span>.join(text).decode(<span class="string">'utf-8'</span>) + <span class="string">'\n'</span>)
            texts_num += <span class="number">1</span>
            <span class="keyword">if</span> texts_num % <span class="number">10000</span> == <span class="number">0</span>:
                logging.info(<span class="string">"已處理 %d 篇文章"</span> % texts_num)

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:
    main()
</code></pre>
<p>在shell 輸入</p>
<pre><code>python3 wiki_to_txt.py zhwiki-20160820-pages-articles.xml.bz2
</code></pre><p>這約需花費20分鐘(on Mac Air)，先讓我們看看接下來還要做些什麼。</p>
<h2 id="u958B_u59CB_u65B7_u8A5E"><a href="#u958B_u59CB_u65B7_u8A5E" class="headerlink" title="開始斷詞"></a>開始斷詞</h2><p>我們有清完標籤的語料了，第二件事就是要把語料中每個句子，進一步拆解成一個一個詞，這個步驟稱為「斷詞」。中文斷詞的工具比比皆是，這裏我採用的是 <a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">jieba</a>，儘管它在繁體中文的斷詞上還是有些不如<code>CKIP</code>，但他實在太簡單、太方便、太好調用了，足以彌補這一點小缺憾：</p>
<pre><code>快速安裝結巴
pip3 install jieba
</code></pre><pre><code class="python"><span class="comment"># 斷詞示例</span>
<span class="keyword">import</span> jieba

seg_list = jieba.cut(<span class="string">"我来到北京清华大学"</span>, cut_all=<span class="keyword">False</span>)
print(<span class="string">"Default Mode: "</span> + <span class="string">"/ "</span>.join(seg_list))  <span class="comment"># 精确模式</span>

<span class="comment">#輸出 Default Mode: 我/ 来到/ 北京/ 清华大学</span>
</code></pre>
<p>現在，我們上一階段的檔案也差不多出爐了，以vi打開看起來會是這個樣子：</p>
<pre><code>歐幾里得 西元前三世紀的希臘數學家 現在被認為是幾何之父 此畫為拉斐爾的作品 雅典學院 数学 是利用符号语言研究數量 结构 变化以及空间等概念的一門学科 从某种角度看屬於形式科學的一種 數學透過抽象化和邏輯推理的使用 由計數 計算 數學家們拓展這些概念......
</code></pre><p>Opps！出了一點狀況，我們發現簡體跟繁體混在一起了，比如「数学」與「數學」會被 word2vec 當成兩個不同的詞，所以我們在斷詞前，還需加上一道繁簡轉換的手續。然而我們的語料集相當龐大，一般的繁簡轉換會有些力不從心，建議採用<a href="https://github.com/BYVoid/OpenCC" target="_blank" rel="external">OpenCC</a>，轉換的方式很簡單：</p>
<pre><code>opencc -i wiki_texts.txt -o wiki_zh_tw.txt -c s2tw.json
</code></pre><p>如果是要將繁體轉為簡體，只要將config的參數從<code>s2tw.json</code>改成<code>t2s.json</code>即可。現在再檢查一次<code>wiki_zh_tw.txt</code>，的確只剩下繁體字了，終於能進入斷詞，輸入<code>python3 segment.py</code>。</p>
<pre><code class="python">
<span class="comment"># -*- coding: utf-8 -*-</span>

<span class="keyword">import</span> jieba
<span class="keyword">import</span> logging

<span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span>

    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)

    <span class="comment"># jieba custom setting.</span>
    jieba.set_dictionary(<span class="string">'jieba_dict/dict.txt.big'</span>)

    <span class="comment"># load stopwords set</span>
    stopwordset = set()
    <span class="keyword">with</span> open(<span class="string">'jieba_dict/stopwords.txt'</span>,<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> sw:
        <span class="keyword">for</span> line <span class="keyword">in</span> sw:
            stopwordset.add(line.strip(<span class="string">'\n'</span>))

    output = open(<span class="string">'wiki_seg.txt'</span>,<span class="string">'w'</span>)
    <span class="keyword">with</span> open(<span class="string">'wiki_zh_tw.txt'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> content :
        <span class="keyword">for</span> line <span class="keyword">in</span> content:
            words = jieba.cut(line, cut_all=<span class="keyword">False</span>)
            <span class="keyword">for</span> word <span class="keyword">in</span> words:
                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwordset:
                    output.write(word +<span class="string">' '</span>)

            texts_num += <span class="number">1</span>
            <span class="keyword">if</span> texts_num % <span class="number">10000</span> == <span class="number">0</span>:
                logging.info(<span class="string">"已處理 %d 個 token"</span> % texts_num)
    output.close()

<span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:
    main()
</code></pre>
<h3 id="Stopwords_and_Window"><a href="#Stopwords_and_Window" class="headerlink" title="Stopwords and Window"></a>Stopwords and Window</h3><p>好啦，這個東西大概要跑個 80 分鐘，<s>先讓我講些幹話</s>，先讓我們看看上頭做了什麼。除了之前演示的斷詞外，這邊還多做了兩件事，一是調整jieba的辭典，讓他對繁體斷詞比較友善，二是引入了<a href="https://zh.wikipedia.org/wiki/%E5%81%9C%E7%94%A8%E8%AF%8D" target="_blank" rel="external">停用詞</a>，停用詞就是像英文中的 the,a,this，中文的你我他，與其他詞相比顯得不怎麼重要，對文章主題也無關緊要的，就可以將它視為停用詞。而要排除停用詞的理由，其實與word2vec的實作概念大大相關，由於在開頭講明了不深究概念，就讓我舉個例子替代長篇大論。</p>
<p>首先，在word2vec有一個概念叫 windows，我習慣叫他窗口，因為它給我的感覺跟TCP 那個會滑來滑去的東東很像。</p>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><p>很顯然，一個詞的意涵跟他的左右鄰居很有關係，比如「雨越下越大，茶越充越淡」，什麼會「下」？「雨」會下，什麼會「淡」？茶會「淡」，這樣的類比舉不勝舉，那麼，若把思維逆轉過來呢？</p>
<p><img src="http://i.imgur.com/KR2ISOg.jpg" alt="逆轉"></p>
<p>顯然，我們或多或少能從左右鄰居是誰，猜出中間的是什麼，這很像我們國高中時天天在練的英文克漏字。那麼問題來了，左右鄰居有誰？能更精確地說，你要往左往右看幾個？假設我們以「孔乙己 一到 店 所有 喝酒 的 人 便都 看著 他 笑」為例，如果往左往右各看一個：</p>
<pre><code>[孔乙己 一到] 店 所有 喝酒 的 人 便 都 看著 他 笑
[孔乙己 一到 店] 所有 喝酒 的 人 便 都 看著 他 笑
孔乙己 [一到 店 所有] 喝酒 的 人 便 都 看著 他 笑
孔乙己 一到 [店 所有 喝酒] 的 人 便 都 看著 他 笑
......
</code></pre><p>這樣就構成了一個 size=1 的 windows，這個 1 是極端的例子，為了讓我們看看有停用詞跟沒停用詞差在哪，這句話去除了停用詞應該會變成：</p>
<pre><code>孔乙己 一到 店 所有 喝酒 人 看著 笑
</code></pre><p>我們看看「人」的窗口變化，原本是「的 人 便」，後來是「喝酒 人 看著」，相比原本的情形，去除停用詞後，我們對「人」這個詞有更多認識，比如人會喝酒，人會看東西，當然啦，這是我以口語的表達，機器並不會這麼想，機器知道的是人跟喝酒會有某種關聯，跟看會有某種關聯，但儘管如此，也遠比本來的「的 人 便」好太多太多了。</p>
<p>就在剛剛，我的斷詞已經跑完了，現在，讓我們進入收尾的階段吧</p>
<pre><code>2016-08-26 22:27:59,480 : INFO : 已處理 260000 個 token
</code></pre><h2 id="u8A13_u7DF4_u8A5E_u5411_u91CF"><a href="#u8A13_u7DF4_u8A5E_u5411_u91CF" class="headerlink" title="訓練詞向量"></a>訓練詞向量</h2><p>這是最簡單的部分，同時也是最困難的部分，簡單的是程式碼，困難的是詞向量效能上的微調與後訓練。對了，如果你已經對詞向量和語言模型有些研究，在輸入<code>python3 train.py</code>之前，建議先看一下之後的內文，相信我，你會需要的。</p>
<pre><code class="python"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec
<span class="keyword">import</span> logging


<span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span>

    logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)

    sentences = word2vec.Text8Corpus(<span class="string">"wiki_seg.txt"</span>)
    model = word2vec.Word2Vec(sentences, size=<span class="number">250</span>)
    model.save_word2vec_format(<span class="string">u"med250.model.bin"</span>, binary=<span class="keyword">True</span>)
    <span class="comment"># how to load a model ?</span>
    <span class="comment"># model = word2vec.Word2Vec.load_word2vec_format("your_model.bin", binary=True)</span>

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:
    main()
</code></pre>
<p>扣掉<code>logging</code>與註釋就剩下三行，真是精簡的漂亮。上頭通篇的學問在<code>model = word2vec.Word2Vec(sentences, size=250)</code>，我們先讓它現出原型：</p>
<pre><code class="python"><span class="class"><span class="keyword">class</span> <span class="title">gensim</span>.<span class="title">models</span>.<span class="title">word2vec</span>.<span class="title">Word2Vec</span><span class="params">(sentences=None, size=<span class="number">100</span>, alpha=<span class="number">0.025</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, max_vocab_size=None, sample=<span class="number">0.001</span>, seed=<span class="number">1</span>, workers=<span class="number">3</span>, min_alpha=<span class="number">0.0001</span>, sg=<span class="number">0</span>, hs=<span class="number">0</span>, negative=<span class="number">5</span>, cbow_mean=<span class="number">1</span>, hashfxn=&lt;built-in function hash&gt;, iter=<span class="number">5</span>, null_word=<span class="number">0</span>, trim_rule=None, sorted_vocab=<span class="number">1</span>, batch_words=<span class="number">10000</span>)</span></span>
</code></pre>
<p>這抵得上 train.py 的所有程式碼了。不過也別太擔心，裏頭多數是無關緊要的參數，比較關鍵的大概是：</p>
<ul>
<li>sentences:當然了，這是要訓練的句子集，沒有他就不用跑了</li>
<li>size:這表示的是訓練出的詞向量會有幾維</li>
<li>alpha:機器學習中的學習率，這東西會逐漸收斂到 <code>min_alpha</code></li>
<li>sg:這個不是三言兩語能說完的，sg=1表示採用skip-gram,sg=0 表示採用cbow </li>
<li>window:還記得孔乙己的例子嗎？往左往右看幾個字的意思，印象中原作者論文裡寫 cbow 採用 5 是不錯的選擇</li>
<li>workers:執行緒數目，除非電腦不錯，不然建議別超過 4</li>
<li>min_count:若這個詞出現的次數小於<code>min_count</code>，那他就不會被視為訓練對象</li>
</ul>
<h2 id="u8A5E_u5411_u91CF_u5BE6_u9A57"><a href="#u8A5E_u5411_u91CF_u5BE6_u9A57" class="headerlink" title="詞向量實驗"></a>詞向量實驗</h2><p>訓練完成後，讓我們來測試一下模型的效能，運行<code>python3 demo.py</code>。由於 gensim 將整個模型讀了進來並作了一層映射，所以記憶體會消耗相當多，如果出現了<code>MemoryError</code>，可能得調整一下<code>min_count</code>或對常用詞作一層快取，這點要特別注意一下。</p>
<p>先來試試相似詞排序吧！</p>
<pre><code>飲料
相似詞前 100 排序
飲品,0.8439314365386963
果汁,0.7858869433403015
罐裝,0.7305712699890137
冰淇淋,0.702262818813324
酸奶,0.7007108926773071
口香糖,0.6987590193748474
酒類,0.6967358589172363
可口可樂,0.6885123252868652
酒精類,0.6843742728233337
含酒精,0.6825539469718933
啤酒,0.6816493272781372
薯片,0.6779764294624329
紅茶,0.6656282544136047
奶茶,0.656740128993988
提神,0.6566425561904907
牛奶,0.6556192636489868
檸檬茶,0.6494661569595337

籃球
相似詞前 100 排序
美式足球,0.6463411450386047
橄欖球,0.6382837891578674
男子籃球,0.6187020540237427
冰球,0.6056296825408936
棒球,0.5859025716781616
籃球運動,0.5831792950630188
籃球員,0.5782726407051086
籃球隊,0.576259195804596
排球,0.5743488073348999
黑子,0.5609416961669922
籃球比賽,0.5498511791229248
打球,0.5496408939361572
中國籃球,0.5471529960632324
男籃,0.5460700392723083
ncaa,0.543986439704895
投投,0.5439497232437134
曲棍球,0.5435376167297363
nba,0.5415610671043396
</code></pre><p>前100太多了，所以只把前幾個結果貼上來，我們也能調用<code>model.similarity(word2,word1)</code>來直接取得兩個詞的相似度：</p>
<pre><code>冰沙 刨冰
計算 Cosine 相似度
0.631961417455

電腦 飛鏢
計算 Cosine 相似度
0.154503715708

電腦 程式
計算 Cosine 相似度
0.5021829415

衛生紙 漫畫
計算 Cosine 相似度
0.167776641495
</code></pre><p>能稍微區隔出詞與詞之間的主題，整體來說算是可以接受的了。</p>
<h3 id="u66F4_u4E0A_u4E00_u5C64_u6A13"><a href="#u66F4_u4E0A_u4E00_u5C64_u6A13" class="headerlink" title="更上一層樓"></a>更上一層樓</h3><p>如何優化詞向量的表現？這其實有蠻多方法的，大方向是從應用的角度出發，我們能針對應用特化的語料進行再訓練，除此之外，斷詞器的選擇也很重要，它很大程度的決定什麼詞該在什麼地方出現，如果發現 <code>jieba</code> 有些力不能及的，不妨試著採用別的斷詞器，或是試著在 <code>jieba</code> 自訂辭典，調一下每個詞的權重。</p>
<p>應用考慮好了，接著看看模型，我們可以調整 <code>model()</code> 的參數，比方窗口大小、維度、學習率，進一步還能比較 skip-gram 與 cbow 的效能差異，什麼，你說不知道 skip-gram 跟 cbow 是什麼？且看下回分解。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/08/30/chatterbot-with-word2vec/" rel="next" title="基於詞向量的主題匹配">
                <i class="fa fa-chevron-left"></i> 基於詞向量的主題匹配
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            本站概覽
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/1428482092251.gif"
               alt="Justin Yang" />
          <p class="site-author-name" itemprop="name">Justin Yang</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">14</span>
              <span class="site-state-item-name">文章</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分類</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">標籤</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zake7749" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://plus.google.com/110210184472476277760" target="_blank" title="Google">
                  
                    <i class="fa fa-fw fa-google-plus"></i>
                  
                  Google
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#u53D6_u5F97_u8A9E_u6599"><span class="nav-number">1.</span> <span class="nav-text">取得語料</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#u958B_u59CB_u65B7_u8A5E"><span class="nav-number">2.</span> <span class="nav-text">開始斷詞</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Stopwords_and_Window"><span class="nav-number">2.1.</span> <span class="nav-text">Stopwords and Window</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word2Vec"><span class="nav-number">3.</span> <span class="nav-text">Word2Vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#u8A13_u7DF4_u8A5E_u5411_u91CF"><span class="nav-number">4.</span> <span class="nav-text">訓練詞向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#u8A5E_u5411_u91CF_u5BE6_u9A57"><span class="nav-number">5.</span> <span class="nav-text">詞向量實驗</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#u66F4_u4E0A_u4E00_u5C64_u6A13"><span class="nav-number">5.1.</span> <span class="nav-text">更上一層樓</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart" style="color:rgb(255,160,180);"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Justin Yang</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div id="open-sidebar" class="open-sidebar close-this-one">
      <i class="fa fa-map"></i>
    </div>
    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'zake7749';
      var disqus_identifier = '2016/10/25/word2vec-with-gensim/';
      var disqus_title = "";
      var disqus_url = 'http://zake7749.github.io/2016/10/25/word2vec-with-gensim/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  <script type="text/javascript" src="/js/src/jquery.tipsy.js"></script>
  <script type="text/javascript" src="/js/src/custom.js"></script>
  

  

</body>
</html>
